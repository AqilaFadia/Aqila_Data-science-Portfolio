# -*- coding: utf-8 -*-
"""An Analysis of Stock Prices.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ef6dlV6iXI_8cs_vFgUUdgmw7qTuR8_E

# An Analysis of Stock Prices.

### Business understanding
The SP500.csv dataset contains historical data on the stock prices of the top 500 companies listed on the New York Stock Exchange (NYSE) and NASDAQ. As a data scientist, our goal is to use this dataset to gain insights into the stock market trends and help investors make informed decisions.

### Problem statement
With the volatility of the stock market, investors are often looking for ways to make data-driven decisions about their investments. However, analyzing large amounts of stock market data can be time-consuming and overwhelming. Therefore, the problem statement is to create a model that can analyze the stock prices of the top 500 companies and provide valuable insights to investors.

### Solution
Our solution to the problem statement is to use machine learning algorithms and statistical analysis to create a predictive model that can identify trends and patterns in the stock market data. We will also perform data visualization to present the insights in an easy-to-understand format. By using this approach, we can help investors make informed decisions based on historical data and current trends in the stock market.

#### Import Library
"""

import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style('whitegrid')
import matplotlib.pyplot as plt
plt.style.use("fivethirtyeight")
import sklearn
import tensorflow as tf

from sklearn import datasets
from keras.models import Sequential
from keras.callbacks import EarlyStopping
from keras.layers import Dense, LSTM, Dropout

from sklearn.preprocessing import MinMaxScaler

data_dir = 'sp500.csv'
df = pd.read_csv(data_dir)

"""Read Data"""

df.info()

df.head()

data_train.isnull().sum()

"""no null data"""

df.describe()

"""#### Visualization"""

dates = data_train['Date'].values
temp  = data_train['Open'].values
 
 
plt.figure(figsize=(15,5))
plt.plot(dates, temp)
plt.title('Open average',
          fontsize=20);

"""split data into data train data test"""

from sklearn.model_selection import train_test_split

X, y = np.arange(10).reshape((5, 2)), range(5)

X

list(y)

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)

n_cols = 1
dataset = df["Open"]
dataset = pd.DataFrame(dataset)
data = dataset.values

data.shape

"""Using MinMaxScaler"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range= (0, 1))
scaled_data = scaler.fit_transform(np.array(data))

"""The validation set is 20% of the total dataset"""

train_size = int(len(data) * 20/100)
test_size = len(data) - train_size
print("Train Size :",train_size,"Test Size :",test_size)

train_data = scaled_data[0:train_size, :]
train_data.shape

x_train = []
y_train = []
time_steps = 60
n_cols = 1

for i in range(time_steps, len(scaled_data)):
    x_train.append(scaled_data[i-time_steps:i, :n_cols])
    y_train.append(scaled_data[i, :n_cols])
    if i<=time_steps:
        print('X_train: ', x_train)
        print('y_train:' , y_train)

x_train, y_train = np.array(x_train), np.array(y_train)

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_cols))

x_train.shape , y_train.shape

model = Sequential([
    LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], n_cols)),
    LSTM(64, return_sequences= False),
    Dense(32),
    Dense(16),
    Dense(n_cols)
])
optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

model.summary()

minMae = (df['Open'].max() - df['Open'].min()) * 10/100
good_mae = minMae
good_mae

history = model.fit(x_train, y_train, epochs= 5, batch_size= 32)

"""The output shows a loss value of 1.4219e-04 and an MAE (mean absolute error) of 0.0122. Loss values ​​that are closer to zero and smaller MAE values ​​indicate that the model is capable of making predictions with high accuracy.

To explain the output results in more detail, the loss value shows how accurate the model is in predicting stock prices based on the data provided. The smaller the loss value, the more accurate the predictions produced by the model. The MAE value shows how much the difference is between the predicted value and the actual value of the stock price in dollars. The smaller the MAE value, the closer the predicted value is to the actual value.

However, to evaluate whether the model can be used to predict future stock prices, it is necessary to carry out further evaluation using data that the model has never seen. In addition, in conducting stock analysis it is also necessary to consider other factors such as market conditions, company policies, and global economic factors that can affect stock prices.
"""