{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Airline Company"
      ],
      "metadata": {
        "id": "8MAjfZ9BcWlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains customer data from an airline company, along with several features that can describe the value of each customer. These features have the potential to provide valuable insights for the airline company to optimize its business strategies, such as marketing, customer retention, or the development of better products and services. By effectively utilizing this dataset, the company can make more informed and accurate decisions in managing its business."
      ],
      "metadata": {
        "id": "eUH8n5l9cRAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGPymrvObruX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data"
      ],
      "metadata": {
        "id": "J7bY4jLhch01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('flight.csv')\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "ZAwZNZWhchTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "qA6Lc_ktc65x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Descriptive Statistic"
      ],
      "metadata": {
        "id": "PVuYHvc8c9Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data type and the number of rows in each column\n",
        "df.info()"
      ],
      "metadata": {
        "id": "pp9Pe3GTcTrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The column containing the date does not yet have the appropriate data type and the 'MEMBER_NO' column needs to be converted to a string\n",
        "* Columns 'GENDER', 'WORK_CITY', 'WORK_PROVINCE', 'WORK_COUNTRY', 'AGE', 'SUM_YR_1', 'SUM_YR_2' are indicated to have empty data that needs to be filled"
      ],
      "metadata": {
        "id": "ecdvii4idb0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change data type\n",
        "df['MEMBER_NO'] = df['MEMBER_NO'].astype(str)\n",
        "df['FFP_DATE'] = pd.to_datetime(df['FFP_DATE'], errors='coerce')\n",
        "df['FIRST_FLIGHT_DATE'] = pd.to_datetime(df['FIRST_FLIGHT_DATE'], errors='coerce')\n",
        "df['LOAD_TIME'] = pd.to_datetime(df['LOAD_TIME'], errors='coerce')\n",
        "df['LAST_FLIGHT_DATE'] = pd.to_datetime(df['LAST_FLIGHT_DATE'], errors='coerce')\n",
        "\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "QrCFX1ZBdU2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after the data type is changed, there is an additional column that has an empty value which most likely comes from an invalid date, namely the column 'LAST_FLIGHT_DATE' and the data will be dropped"
      ],
      "metadata": {
        "id": "_uv2IftFdy8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop empty data based on column 'LAST_FLIGHT_DATE'\n",
        "df.dropna(subset=['LAST_FLIGHT_DATE'], inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "cwaT-kESdsoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicate data\n",
        "df['MEMBER_NO'].duplicated().sum()"
      ],
      "metadata": {
        "id": "fFIocAt-fyu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "no duplicate data"
      ],
      "metadata": {
        "id": "95-Wz2sxgAuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group columns by type\n",
        "cats = ['MEMBER_NO', 'GENDER', 'WORK_CITY', 'WORK_PROVINCE', 'WORK_COUNTRY']\n",
        "nums = ['FFP_TIER', 'AGE', 'FLIGHT_COUNT', 'BP_SUM', 'SUM_YR_1', 'SUM_YR_2', 'SEG_KM_SUM', 'LAST_TO_END', 'AVG_INTERVAL', 'MAX_INTERVAL',\n",
        "       'EXCHANGE_COUNT', 'avg_discount', 'Points_Sum', 'Point_NotFlight']\n",
        "timestamp = ['FFP_DATE', 'FIRST_FLIGHT_DATE', 'LOAD_TIME', 'LAST_FLIGHT_DATE']"
      ],
      "metadata": {
        "id": "UXptcZvkgB6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical column statistics\n",
        "df[cats].describe()"
      ],
      "metadata": {
        "id": "YYnKngLFgJor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The demographics of the majority of customers are men who live in China, precisely in the city of Guangzhou"
      ],
      "metadata": {
        "id": "HHqnPfacgX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numeric column statistics\n",
        "df[nums].describe()"
      ],
      "metadata": {
        "id": "3ZXpiEoLgThT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "between the Q3 value and the maximum value there is a significant difference so that there are indications of outliers for all numerical features"
      ],
      "metadata": {
        "id": "Cpy4-7awhKIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate Analysis"
      ],
      "metadata": {
        "id": "myUIDZiThfMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the number of rows of each unique value categorical column\n",
        "for col in cats:\n",
        "    print(f'''Value count kolom {col}:''')\n",
        "    print(df[col].value_counts())\n",
        "    print()"
      ],
      "metadata": {
        "id": "Wx4qsfyphFh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot for each numeric column\n",
        "plt.figure(figsize=(12,45))\n",
        "for i in range(0, len(nums)):\n",
        "    plt.subplot(len(nums), 5,i+1)\n",
        "    sns.boxplot(y=df[nums[i]], color='gray', orient='v')\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "OFYi9OOVhrcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "indicated that there are outliers in all numeric columns"
      ],
      "metadata": {
        "id": "UI1liA1oiO7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution of each numeric column\n",
        "plt.figure(figsize=(12,45))\n",
        "for i in range(0, len(nums)):\n",
        "    plt.subplot(len(nums),5, i+1)\n",
        "    sns.distplot(df[nums[i]], color='gray')\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "frt2h-7xh01A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost all columns are not normally distributed, except for the 'AGE' and 'avg_discount' columns"
      ],
      "metadata": {
        "id": "bFa787KBilmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fill column 'GENDER', 'WORK_CITY', 'WORK_PROVINCE', 'WORK_COUNTRY' with mode (value that appears most often)\n",
        "df['GENDER'].fillna(df['GENDER'].mode()[0], inplace=True)\n",
        "df['WORK_CITY'].fillna(df['WORK_CITY'].mode()[0], inplace=True)\n",
        "df['WORK_PROVINCE'].fillna(df['WORK_PROVINCE'].mode()[0], inplace=True)\n",
        "df['WORK_COUNTRY'].fillna(df['WORK_COUNTRY'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "XueizNNAietG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill column 'AGE' with average and 'SUM_YR_1', 'SUM_YR_2' with median\n",
        "df['AGE'].fillna(df['AGE'].mean(), inplace=True)\n",
        "df['SUM_YR_1'].fillna(df['SUM_YR_1'].median(), inplace=True)\n",
        "df['SUM_YR_2'].fillna(df['SUM_YR_2'].median(), inplace=True)"
      ],
      "metadata": {
        "id": "VTaji58ti9rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "wormfFKijFwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now there is no more empty data"
      ],
      "metadata": {
        "id": "Qekm4PISjNGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove oulier based on IQR because the majority of the data is not normally distributed\n",
        "print(f'Number of rows before filtering outliers: {len(df)}')\n",
        "\n",
        "filtered_entries = np.array([True] * len(df))\n",
        "for col in nums:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    low_limit = Q1 - (IQR * 1.5)\n",
        "    high_limit = Q3 + (IQR * 1.5)\n",
        "\n",
        "    filtered_entries = ((df[col] >= low_limit) & (df[col] <= high_limit)) & filtered_entries\n",
        "\n",
        "df = df[filtered_entries]\n",
        "\n",
        "print(f'Number of rows after filtering outliers: {len(df)}')"
      ],
      "metadata": {
        "id": "CaeQTUqjjJUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding of all categorical columns\n",
        "\n",
        "cats = ['MEMBER_NO', 'GENDER', 'WORK_CITY', 'WORK_PROVINCE', 'WORK_COUNTRY']\n",
        "df_enc = df.copy()\n",
        "for i in cats[1:]:\n",
        "    df_enc[i] = df_enc[i].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "nrL_wrpAjhtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_enc.head()"
      ],
      "metadata": {
        "id": "ZmkrjJGmjnsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multivariate Analysis"
      ],
      "metadata": {
        "id": "9NmZ-E6mjuRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df_enc.corr()\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr, mask=mask, cmap='Blues', annot=True, fmt='.2f')"
      ],
      "metadata": {
        "id": "gW3MZG4Bjrzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the correlation above, several redundant features are obtained, namely:\n",
        "\n",
        "* SUM_YR_1 with FLIGHT_COUNT, BP_SUM\n",
        "* SUM_YR_2 with FLIGHT_COUNT, BP_SUM\n",
        "* SEG_KM_SUM with FLIGHT_COUNT, BP_SUM, SUM_YR_1, SUM_YR_2\n",
        "* LAST_TO_END with SUM_YR_2\n",
        "* MAX_INTERVAL with AVG_INTERVAL\n",
        "* POINT_SUM with FLIGHT_COUNT, BP_SUM, SUM_YR_1, SUM_YR_2, SEG_KM_SUM\n",
        "\n",
        "Based on the conditions above, the FLIGHT_COUNT, BP_SUM, SUM_YR_1, SUM_YR_2 and POINT_SUM columns will be dropped to avoid redundant features\n",
        "\n",
        "there are also features whose correlation values ​​do not appear, namely 'FFP_TIER' and 'EXCHANGE_COUNT' so these features will be removed"
      ],
      "metadata": {
        "id": "b-TDWdHNkAp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "yl_UstHAkyPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop some features\n",
        "df_new = df_enc.drop(columns=['FLIGHT_COUNT','BP_SUM','SUM_YR_1','SUM_YR_2','FFP_TIER','EXCHANGE_COUNT','Points_Sum',\n",
        "                          'FFP_DATE', 'FIRST_FLIGHT_DATE', 'LOAD_TIME', 'LAST_FLIGHT_DATE',\n",
        "                          'MEMBER_NO']).copy()\n",
        "df_new"
      ],
      "metadata": {
        "id": "TAjmoS6dj3IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are still 11 features so that dimensionality reduction will then be carried out with PCA\n"
      ],
      "metadata": {
        "id": "atHdHy9PlBgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.columns"
      ],
      "metadata": {
        "id": "q_gv_kFmk86M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature standardization first\n",
        "feature = ['GENDER', 'WORK_CITY', 'WORK_PROVINCE', 'WORK_COUNTRY', 'AGE',\n",
        "       'SEG_KM_SUM', 'LAST_TO_END', 'AVG_INTERVAL', 'MAX_INTERVAL',\n",
        "       'avg_discount', 'Point_NotFlight']\n",
        "X = df_new.values\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_std = StandardScaler().fit_transform(X)\n",
        "df_std = pd.DataFrame(data = X_std, columns = feature).head()\n",
        "df_std.describe()"
      ],
      "metadata": {
        "id": "vgXxjBRvlmCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_std"
      ],
      "metadata": {
        "id": "Px-DbMCul5S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pcs = PCA(n_components=4).fit_transform(X_std)\n",
        "df_pca = pd.DataFrame(data = pcs, columns = ['pc1','pc2','pc3','pc4'])\n",
        "df_pca.describe()"
      ],
      "metadata": {
        "id": "cNGBPHMjmKw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling dan Evaluasi"
      ],
      "metadata": {
        "id": "FvkoKsmgmRJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "find the number of clusters with the elbow method"
      ],
      "metadata": {
        "id": "RDzrgjH7mdH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inertia = []\n",
        "\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    kmeans.fit(df_pca.values)\n",
        "    inertia.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "1pDcE6_kmOa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of the results of the elbow method\n",
        "sns.lineplot(x=range(1,11), y=inertia, linewidth=3)\n",
        "sns.scatterplot(x=range(1,11), y=inertia, s=60)"
      ],
      "metadata": {
        "id": "PpMPWuX0mlOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.Series(inertia) - pd.Series(inertia).shift(-1)) / pd.Series(inertia) * 100"
      ],
      "metadata": {
        "id": "vXR2SBn3my9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the elbow method above, 3 clusters are obtained"
      ],
      "metadata": {
        "id": "NGrN3NUsm55C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### clustering dengan K-means"
      ],
      "metadata": {
        "id": "0nWfA8ETm9j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "kmeans.fit(df_pca.values)\n",
        "df_pca['labels_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "b4Rvrz-Gm7JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pca"
      ],
      "metadata": {
        "id": "cIW3dnXWnJ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cluster evaluation"
      ],
      "metadata": {
        "id": "R498sBiWnRdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of clustering results\n",
        "sns.scatterplot(data=df_pca, x='pc1', y='pc2', hue='labels_cluster')"
      ],
      "metadata": {
        "id": "QMZUhIKunNdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the silhouette score\n",
        "X_sil = df_pca.drop(columns='labels_cluster').values\n",
        "labels = df_pca['labels_cluster'].values\n",
        "silhouette_avg = silhouette_score(X_sil, labels)\n",
        "silhouette_avg"
      ],
      "metadata": {
        "id": "P72Ubwh_nc3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# silhouette score visualization\n",
        "sample_silhouette_values = silhouette_samples(X_sil, labels)\n",
        "\n",
        "n_clusters = 3\n",
        "y_lower = 10\n",
        "fig, ax1 = plt.subplots(1, 1)\n",
        "fig.set_size_inches(6, 4)\n",
        "ax1.set_xlim([-0.1, 1])\n",
        "ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    ith_cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
        "    ith_cluster_silhouette_values.sort()\n",
        "\n",
        "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "    y_upper = y_lower + size_cluster_i\n",
        "\n",
        "    color = plt.cm.get_cmap(\"Spectral\")(float(i) / n_clusters)\n",
        "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "    y_lower = y_upper + 10\n",
        "\n",
        "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "ax1.set_xlabel(\"Silhouette Coefficient Values\")\n",
        "ax1.set_ylabel(\"Cluster Label\")\n",
        "ax1.set_yticks([])\n",
        "plt.title((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "               \"with n_clusters = %d\" % n_clusters),\n",
        "              fontsize=10, fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AebhoXqrnls6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restore data to original\n",
        "for col in cats[1:]:\n",
        "    codes = df_enc[col].unique()\n",
        "    labels = df[col].unique()\n",
        "    mapping = dict(zip(codes, labels))\n",
        "    df_enc[col] = df_enc[col].replace(mapping)\n",
        "\n",
        "df_enc['labels_cluster'] = kmeans.labels_\n",
        "df_enc.sample(5)\n"
      ],
      "metadata": {
        "id": "5Kxb02mloKLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### statistical summary"
      ],
      "metadata": {
        "id": "MHmPOpl9oT3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numeric column\n",
        "df_nums = df_enc[nums]\n",
        "df_nums['label'] = df_enc['labels_cluster']\n",
        "\n",
        "df_nums.groupby('label').agg(['mean', 'median', 'std'])"
      ],
      "metadata": {
        "id": "J-VJFHTjoQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cats = df[cats].drop(columns='MEMBER_NO')\n",
        "df_cats['label'] = df_enc['labels_cluster']\n",
        "\n",
        "df_cats.groupby('label').agg(pd.Series.mode)"
      ],
      "metadata": {
        "id": "KygPLC4wocFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### based on the statistical summary above, the characteristics of each cluster are obtained as follows:\n",
        "\n",
        "* Cluster 0: The highest average itinerary, number of flights, total flight distance. For the last flight time distance to the lowest last flight order. Lives in guangzhou city\n",
        "* Cluster 1: Average itinerary, number of flights, total moderate flight distance, For the distance of the last flight time to the last moderate flight order. Lives in beijing city\n",
        "* Cluster 2: The lowest average itinerary, number of flights, total flight distance. For the distance between the last flight and the highest last flight order. Lives in guangzhou city"
      ],
      "metadata": {
        "id": "ZYhDxidzozoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation:\n",
        "\n",
        "* Increase the promotion of tour packages in Beijing: Cluster 1 shows that users in Beijing tend to travel medium-distance flights. Therefore, promotion of tour packages with medium-distance destinations around Beijing can be an effective strategy to attract user interest.\n",
        "\n",
        "* Offering discounts on short-haul flights: Cluster 2 shows that users in Guangzhou city are more likely to book shorter-haul flights. In this case, businesses can offer special discounts on short-haul flights to attract users in Guangzhou city.\n",
        "\n",
        "* Improve flight service from Guangzhou: Cluster 0 shows that users in Guangzhou city tend to have more compact itineraries and require more flights over longer distances. In this case, businesses can increase flight services from Guangzhou to destinations that are farther away to meet the needs of users in this city.\n",
        "\n",
        "* Offer accommodation and transportation packages for users in both cities: Based on the clustering results, users in both cities tend to travel with a high number of flights. Therefore, businesses can offer integrated accommodation and transportation packages to make it easier for users to plan their trips."
      ],
      "metadata": {
        "id": "ak50dSiio-m6"
      }
    }
  ]
}